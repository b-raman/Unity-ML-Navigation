{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation Project - Bharat Raman\n",
    "\n",
    "---\n",
    "\n",
    "In this project, I train an agent to navigate an environment filled with yellow and blue bananas. Collecting yellow bananas gives a reward of 1, while collecting blue bananas gives a reward of -1.\n",
    "There are 37 state spaces, and 4 actions\n",
    "- State spaces include the agent's velocity, and its ray-based perception of objects around its forward direction\n",
    "- Actions include forward, backward, turn left, turn right\n",
    "\n",
    "For the agent and model, I referred to the Lunar Landing exercise in this course.\n",
    "- The model is a deep neural network consisting of four fully connected layers with ReLU activation.\n",
    "- The agent will utilize a replay buffer to store tuples <S,A,R,S'> for each time step\n",
    "\n",
    "This notebook is a modified version of the provided notebook for this project\n",
    "\n",
    "## 1. Start the Environment\n",
    "\n",
    "Make sure required packages are installed. See README.md for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "# please do not modify the line below\n",
    "env = UnityEnvironment(file_name=\"Banana.app\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States look like: [1.         0.         0.         0.         0.84408134 0.\n",
      " 0.         1.         0.         0.0748472  0.         1.\n",
      " 0.         0.         0.25755    1.         0.         0.\n",
      " 0.         0.74177343 0.         1.         0.         0.\n",
      " 0.25854847 0.         0.         1.         0.         0.09355672\n",
      " 0.         1.         0.         0.         0.31969345 0.\n",
      " 0.        ]\n",
      "States have length: 37\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define a model, agent and replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    \"\"\"Actor (Policy) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed):\n",
    "        \"\"\"\n",
    "        Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "        \"\"\"\n",
    "        super(QNetwork, self).__init__()\n",
    "        \n",
    "        \"*** YOUR CODE HERE ***\"\n",
    "        #layer 1: Hidden\n",
    "        self.fc1 = nn.Linear(state_size, 64)\n",
    "        #layer 2: Hidden\n",
    "        self.fc2 = nn.Linear(64, 128)\n",
    "        #layer 3: Hidden\n",
    "        self.fc3 = nn.Linear(128, 256)\n",
    "        #layer 4: output\n",
    "        self.fc4 = nn.Linear(256, action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        #Build a network that maps state -> action values.\n",
    "        state = F.relu(self.fc1(state)) #activation for first hidden layer\n",
    "        state = F.relu(self.fc2(state)) #activation for second hidden layer\n",
    "        state = F.relu(self.fc3(state)) #activation for third hidden layer\n",
    "        state = F.relu(self.fc4(state)) #activation for outputyer\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed, prioritize = False):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            action_size (int): dimension of each action\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)  \n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "        self.prioritize = False\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "  \n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
    "BATCH_SIZE = 64         # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR = 5e-4               # learning rate \n",
    "UPDATE_EVERY = 4        # how often to update the network\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Agent():\n",
    "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed):\n",
    "        \"\"\"Initialize an Agent object.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): dimension of each state\n",
    "            action_size (int): dimension of each action\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(seed)\n",
    "\n",
    "        # Q-Network\n",
    "        self.qnetwork_local = QNetwork(state_size, action_size, 0).to(device)\n",
    "        self.qnetwork_target = QNetwork(state_size, action_size, 0).to(device)\n",
    "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr=LR)\n",
    "\n",
    "        # Replay memory\n",
    "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, seed)\n",
    "        # Initialize time step (for updating every UPDATE_EVERY steps)\n",
    "        self.t_step = 0\n",
    "    \n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        # Save experience in replay memory\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "        \n",
    "        # Learn every UPDATE_EVERY time steps.\n",
    "        self.t_step = (self.t_step + 1) % UPDATE_EVERY\n",
    "        if self.t_step == 0:\n",
    "            # If enough samples are available in memory, get random subset and learn\n",
    "            if len(self.memory) > BATCH_SIZE:\n",
    "                experiences = self.memory.sample()\n",
    "                self.learn(experiences, GAMMA)\n",
    "\n",
    "    def act(self, state, eps=0.):\n",
    "        \"\"\"Returns actions for given state as per current policy.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state (array_like): current state\n",
    "            eps (float): epsilon, for epsilon-greedy action selection\n",
    "        \"\"\"\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        self.qnetwork_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.qnetwork_local(state)\n",
    "        self.qnetwork_local.train()\n",
    "\n",
    "        # Epsilon-greedy action selection\n",
    "        if random.random() > eps:\n",
    "            return np.argmax(action_values.cpu().data.numpy())\n",
    "        else:\n",
    "            return random.choice(np.arange(self.action_size))\n",
    "        \n",
    "    def learn(self, experiences, gamma):\n",
    "        \"\"\"Update value parameters using given batch of experience tuples.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            experiences (Tuple[torch.Variable]): tuple of (s, a, r, s', done) tuples \n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        # Get max predicted Q values (for next states) from target model\n",
    "        Q_targets_next = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "        # Compute Q targets for current states \n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "\n",
    "        # Get expected Q values from local model\n",
    "        Q_expected = self.qnetwork_local(states).gather(1, actions)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        # Minimize the loss\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # ------------------- update target network ------------------- #\n",
    "        self.soft_update(self.qnetwork_local, self.qnetwork_target, TAU)                     \n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            local_model (PyTorch model): weights will be copied from\n",
    "            target_model (PyTorch model): weights will be copied to\n",
    "            tau (float): interpolation parameter \n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(state_size, action_size, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train\n",
    "\n",
    "Train the agent to at most 1000 episodes.\n",
    "Plot results\n",
    "\n",
    "Note that **in this coding environment, you will not be able to watch the agent while it is training**, and you should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " At Episode 2\tBest Average Score: 0.50\n",
      " At Episode 3\tBest Average Score: 0.67\n",
      "Episode 10\n",
      "Episode 20\n",
      "Episode 30\n",
      "Episode 40\n",
      "Episode 50\n",
      "Episode 60\n",
      "Episode 70\n",
      "Episode 80\n",
      "Episode 90\n",
      "Episode 100\n",
      "Episode 110\n",
      "Episode 120\n",
      " At Episode 124\tBest Average Score: 0.69\n",
      " At Episode 125\tBest Average Score: 0.71\n",
      " At Episode 126\tBest Average Score: 0.76\n",
      " At Episode 127\tBest Average Score: 0.78\n",
      " At Episode 128\tBest Average Score: 0.82\n",
      " At Episode 129\tBest Average Score: 0.88\n",
      "Episode 130\n",
      " At Episode 130\tBest Average Score: 0.89\n",
      " At Episode 131\tBest Average Score: 0.95\n",
      " At Episode 132\tBest Average Score: 0.99\n",
      " At Episode 133\tBest Average Score: 1.00\n",
      " At Episode 135\tBest Average Score: 1.06\n",
      " At Episode 136\tBest Average Score: 1.09\n",
      " At Episode 137\tBest Average Score: 1.10\n",
      " At Episode 138\tBest Average Score: 1.11\n",
      " At Episode 139\tBest Average Score: 1.14\n",
      "Episode 140\n",
      " At Episode 140\tBest Average Score: 1.15\n",
      " At Episode 141\tBest Average Score: 1.18\n",
      " At Episode 146\tBest Average Score: 1.22\n",
      " At Episode 148\tBest Average Score: 1.26\n",
      " At Episode 149\tBest Average Score: 1.30\n",
      "Episode 150\n",
      " At Episode 150\tBest Average Score: 1.40\n",
      " At Episode 151\tBest Average Score: 1.42\n",
      " At Episode 152\tBest Average Score: 1.46\n",
      " At Episode 153\tBest Average Score: 1.48\n",
      " At Episode 154\tBest Average Score: 1.58\n",
      " At Episode 155\tBest Average Score: 1.59\n",
      " At Episode 156\tBest Average Score: 1.62\n",
      " At Episode 157\tBest Average Score: 1.65\n",
      " At Episode 158\tBest Average Score: 1.72\n",
      " At Episode 159\tBest Average Score: 1.80\n",
      "Episode 160\n",
      " At Episode 160\tBest Average Score: 1.85\n",
      " At Episode 161\tBest Average Score: 1.92\n",
      " At Episode 162\tBest Average Score: 2.00\n",
      " At Episode 164\tBest Average Score: 2.05\n",
      " At Episode 165\tBest Average Score: 2.07\n",
      " At Episode 166\tBest Average Score: 2.10\n",
      " At Episode 167\tBest Average Score: 2.15\n",
      " At Episode 168\tBest Average Score: 2.21\n",
      " At Episode 169\tBest Average Score: 2.23\n",
      "Episode 170\n",
      " At Episode 170\tBest Average Score: 2.28\n",
      " At Episode 171\tBest Average Score: 2.39\n",
      " At Episode 173\tBest Average Score: 2.44\n",
      " At Episode 175\tBest Average Score: 2.46\n",
      " At Episode 176\tBest Average Score: 2.48\n",
      " At Episode 177\tBest Average Score: 2.53\n",
      " At Episode 178\tBest Average Score: 2.55\n",
      " At Episode 179\tBest Average Score: 2.59\n",
      "Episode 180\n",
      " At Episode 180\tBest Average Score: 2.60\n",
      " At Episode 181\tBest Average Score: 2.61\n",
      " At Episode 183\tBest Average Score: 2.63\n",
      " At Episode 184\tBest Average Score: 2.70\n",
      " At Episode 185\tBest Average Score: 2.75\n",
      " At Episode 186\tBest Average Score: 2.80\n",
      " At Episode 187\tBest Average Score: 2.86\n",
      " At Episode 188\tBest Average Score: 2.92\n",
      "Episode 190\n",
      " At Episode 191\tBest Average Score: 3.01\n",
      " At Episode 192\tBest Average Score: 3.08\n",
      " At Episode 193\tBest Average Score: 3.15\n",
      " At Episode 194\tBest Average Score: 3.22\n",
      " At Episode 195\tBest Average Score: 3.27\n",
      " At Episode 196\tBest Average Score: 3.30\n",
      " At Episode 197\tBest Average Score: 3.38\n",
      " At Episode 198\tBest Average Score: 3.44\n",
      " At Episode 199\tBest Average Score: 3.48\n",
      "Episode 200\n",
      " At Episode 200\tBest Average Score: 3.50\n",
      " At Episode 201\tBest Average Score: 3.52\n",
      " At Episode 202\tBest Average Score: 3.55\n",
      " At Episode 203\tBest Average Score: 3.65\n",
      " At Episode 204\tBest Average Score: 3.68\n",
      " At Episode 205\tBest Average Score: 3.74\n",
      " At Episode 206\tBest Average Score: 3.77\n",
      " At Episode 207\tBest Average Score: 3.82\n",
      " At Episode 208\tBest Average Score: 3.94\n",
      " At Episode 209\tBest Average Score: 4.00\n",
      "Episode 210\n",
      " At Episode 210\tBest Average Score: 4.06\n",
      " At Episode 214\tBest Average Score: 4.12\n",
      " At Episode 215\tBest Average Score: 4.15\n",
      " At Episode 216\tBest Average Score: 4.20\n",
      " At Episode 217\tBest Average Score: 4.25\n",
      " At Episode 218\tBest Average Score: 4.35\n",
      " At Episode 219\tBest Average Score: 4.42\n",
      "Episode 220\n",
      " At Episode 220\tBest Average Score: 4.45\n",
      " At Episode 223\tBest Average Score: 4.52\n",
      " At Episode 224\tBest Average Score: 4.54\n",
      " At Episode 225\tBest Average Score: 4.59\n",
      " At Episode 226\tBest Average Score: 4.63\n",
      " At Episode 227\tBest Average Score: 4.70\n",
      " At Episode 228\tBest Average Score: 4.75\n",
      " At Episode 229\tBest Average Score: 4.82\n",
      "Episode 230\n",
      " At Episode 230\tBest Average Score: 4.90\n",
      " At Episode 231\tBest Average Score: 4.94\n",
      " At Episode 233\tBest Average Score: 5.01\n",
      " At Episode 234\tBest Average Score: 5.03\n",
      " At Episode 235\tBest Average Score: 5.08\n",
      " At Episode 236\tBest Average Score: 5.18\n",
      " At Episode 237\tBest Average Score: 5.24\n",
      " At Episode 238\tBest Average Score: 5.25\n",
      " At Episode 239\tBest Average Score: 5.32\n",
      "Episode 240\n",
      " At Episode 240\tBest Average Score: 5.37\n",
      " At Episode 241\tBest Average Score: 5.45\n",
      " At Episode 242\tBest Average Score: 5.53\n",
      " At Episode 243\tBest Average Score: 5.63\n",
      " At Episode 244\tBest Average Score: 5.71\n",
      " At Episode 245\tBest Average Score: 5.77\n",
      " At Episode 246\tBest Average Score: 5.78\n",
      " At Episode 247\tBest Average Score: 5.86\n",
      " At Episode 248\tBest Average Score: 5.97\n",
      "Episode 250\n",
      " At Episode 252\tBest Average Score: 6.04\n",
      " At Episode 253\tBest Average Score: 6.08\n",
      " At Episode 255\tBest Average Score: 6.12\n",
      " At Episode 259\tBest Average Score: 6.14\n",
      "Episode 260\n",
      " At Episode 260\tBest Average Score: 6.17\n",
      " At Episode 262\tBest Average Score: 6.21\n",
      " At Episode 263\tBest Average Score: 6.28\n",
      " At Episode 264\tBest Average Score: 6.32\n",
      " At Episode 265\tBest Average Score: 6.34\n",
      " At Episode 267\tBest Average Score: 6.37\n",
      " At Episode 269\tBest Average Score: 6.40\n",
      "Episode 270\n",
      " At Episode 270\tBest Average Score: 6.41\n",
      " At Episode 272\tBest Average Score: 6.43\n",
      " At Episode 273\tBest Average Score: 6.48\n",
      " At Episode 274\tBest Average Score: 6.53\n",
      " At Episode 275\tBest Average Score: 6.55\n",
      " At Episode 276\tBest Average Score: 6.56\n",
      " At Episode 278\tBest Average Score: 6.60\n",
      " At Episode 279\tBest Average Score: 6.63\n",
      "Episode 280\n",
      " At Episode 280\tBest Average Score: 6.67\n",
      " At Episode 281\tBest Average Score: 6.75\n",
      " At Episode 282\tBest Average Score: 6.87\n",
      " At Episode 283\tBest Average Score: 6.91\n",
      " At Episode 284\tBest Average Score: 7.00\n",
      " At Episode 285\tBest Average Score: 7.01\n",
      " At Episode 286\tBest Average Score: 7.07\n",
      " At Episode 287\tBest Average Score: 7.08\n",
      " At Episode 288\tBest Average Score: 7.10\n",
      " At Episode 289\tBest Average Score: 7.12\n",
      "Episode 290\n",
      " At Episode 290\tBest Average Score: 7.19\n",
      " At Episode 294\tBest Average Score: 7.20\n",
      " At Episode 296\tBest Average Score: 7.26\n",
      " At Episode 297\tBest Average Score: 7.28\n",
      " At Episode 299\tBest Average Score: 7.32\n",
      "Episode 300\n",
      " At Episode 300\tBest Average Score: 7.36\n",
      " At Episode 301\tBest Average Score: 7.48\n",
      " At Episode 302\tBest Average Score: 7.53\n",
      " At Episode 303\tBest Average Score: 7.59\n",
      " At Episode 304\tBest Average Score: 7.67\n",
      " At Episode 306\tBest Average Score: 7.72\n",
      " At Episode 307\tBest Average Score: 7.77\n",
      "Episode 310\n",
      " At Episode 313\tBest Average Score: 7.81\n",
      " At Episode 317\tBest Average Score: 7.82\n",
      " At Episode 319\tBest Average Score: 7.86\n",
      "Episode 320\n",
      " At Episode 320\tBest Average Score: 7.91\n",
      " At Episode 321\tBest Average Score: 7.98\n",
      " At Episode 322\tBest Average Score: 8.02\n",
      " At Episode 323\tBest Average Score: 8.07\n",
      " At Episode 324\tBest Average Score: 8.13\n",
      " At Episode 325\tBest Average Score: 8.18\n",
      "Episode 330\n",
      " At Episode 331\tBest Average Score: 8.19\n",
      " At Episode 332\tBest Average Score: 8.30\n",
      " At Episode 333\tBest Average Score: 8.31\n",
      " At Episode 334\tBest Average Score: 8.35\n",
      " At Episode 335\tBest Average Score: 8.36\n",
      " At Episode 338\tBest Average Score: 8.44\n",
      "Episode 340\n",
      " At Episode 346\tBest Average Score: 8.48\n",
      " At Episode 347\tBest Average Score: 8.55\n",
      " At Episode 348\tBest Average Score: 8.58\n",
      " At Episode 349\tBest Average Score: 8.73\n",
      "Episode 350\n",
      " At Episode 350\tBest Average Score: 8.76\n",
      " At Episode 351\tBest Average Score: 8.83\n",
      " At Episode 352\tBest Average Score: 8.84\n",
      " At Episode 354\tBest Average Score: 8.90\n",
      " At Episode 357\tBest Average Score: 8.93\n",
      " At Episode 358\tBest Average Score: 9.01\n",
      " At Episode 359\tBest Average Score: 9.02\n",
      "Episode 360\n",
      " At Episode 361\tBest Average Score: 9.05\n",
      " At Episode 366\tBest Average Score: 9.18\n",
      " At Episode 368\tBest Average Score: 9.19\n",
      "Episode 370\n",
      " At Episode 370\tBest Average Score: 9.22\n",
      " At Episode 371\tBest Average Score: 9.27\n",
      " At Episode 374\tBest Average Score: 9.28\n",
      " At Episode 375\tBest Average Score: 9.36\n",
      " At Episode 376\tBest Average Score: 9.46\n",
      " At Episode 377\tBest Average Score: 9.58\n",
      " At Episode 378\tBest Average Score: 9.63\n",
      "Episode 380\n",
      " At Episode 388\tBest Average Score: 9.65\n",
      " At Episode 389\tBest Average Score: 9.74\n",
      "Episode 390\n",
      " At Episode 390\tBest Average Score: 9.78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " At Episode 391\tBest Average Score: 9.85\n",
      " At Episode 393\tBest Average Score: 9.87\n",
      " At Episode 395\tBest Average Score: 9.91\n",
      " At Episode 398\tBest Average Score: 9.99\n",
      "Episode 400\n",
      " At Episode 405\tBest Average Score: 10.01\n",
      " At Episode 406\tBest Average Score: 10.11\n",
      " At Episode 407\tBest Average Score: 10.15\n",
      " At Episode 408\tBest Average Score: 10.24\n",
      " At Episode 409\tBest Average Score: 10.34\n",
      "Episode 410\n",
      " At Episode 411\tBest Average Score: 10.35\n",
      " At Episode 412\tBest Average Score: 10.36\n",
      " At Episode 413\tBest Average Score: 10.43\n",
      " At Episode 414\tBest Average Score: 10.51\n",
      " At Episode 416\tBest Average Score: 10.54\n",
      " At Episode 417\tBest Average Score: 10.58\n",
      " At Episode 418\tBest Average Score: 10.67\n",
      "Episode 420\n",
      " At Episode 420\tBest Average Score: 10.69\n",
      " At Episode 421\tBest Average Score: 10.73\n",
      " At Episode 422\tBest Average Score: 10.76\n",
      " At Episode 426\tBest Average Score: 10.78\n",
      "Episode 430\n",
      " At Episode 431\tBest Average Score: 10.81\n",
      " At Episode 436\tBest Average Score: 10.86\n",
      " At Episode 438\tBest Average Score: 10.89\n",
      " At Episode 439\tBest Average Score: 11.00\n",
      "Episode 440\n",
      " At Episode 440\tBest Average Score: 11.01\n",
      " At Episode 441\tBest Average Score: 11.15\n",
      " At Episode 442\tBest Average Score: 11.17\n",
      " At Episode 444\tBest Average Score: 11.20\n",
      " At Episode 445\tBest Average Score: 11.23\n",
      " At Episode 446\tBest Average Score: 11.28\n",
      " At Episode 447\tBest Average Score: 11.33\n",
      "Episode 450\n",
      " At Episode 452\tBest Average Score: 11.37\n",
      " At Episode 453\tBest Average Score: 11.46\n",
      " At Episode 454\tBest Average Score: 11.50\n",
      " At Episode 455\tBest Average Score: 11.55\n",
      " At Episode 456\tBest Average Score: 11.63\n",
      " At Episode 457\tBest Average Score: 11.69\n",
      "Episode 460\n",
      " At Episode 462\tBest Average Score: 11.70\n",
      " At Episode 463\tBest Average Score: 11.77\n",
      " At Episode 464\tBest Average Score: 11.80\n",
      " At Episode 468\tBest Average Score: 11.84\n",
      " At Episode 469\tBest Average Score: 11.88\n",
      "Episode 470\n",
      " At Episode 470\tBest Average Score: 11.93\n",
      " At Episode 472\tBest Average Score: 11.96\n",
      " At Episode 474\tBest Average Score: 11.98\n",
      " At Episode 475\tBest Average Score: 12.00\n",
      " At Episode 478\tBest Average Score: 12.03\n",
      " At Episode 479\tBest Average Score: 12.06\n",
      "Episode 480\n",
      " At Episode 481\tBest Average Score: 12.19\n",
      " At Episode 482\tBest Average Score: 12.29\n",
      " At Episode 488\tBest Average Score: 12.31\n",
      " At Episode 489\tBest Average Score: 12.33\n",
      "Episode 490\n",
      " At Episode 490\tBest Average Score: 12.34\n",
      " At Episode 492\tBest Average Score: 12.39\n",
      " At Episode 493\tBest Average Score: 12.49\n",
      " At Episode 494\tBest Average Score: 12.53\n",
      " At Episode 495\tBest Average Score: 12.62\n",
      " At Episode 496\tBest Average Score: 12.66\n",
      " At Episode 497\tBest Average Score: 12.67\n",
      "Episode 500\n",
      " At Episode 500\tBest Average Score: 12.70\n",
      " At Episode 501\tBest Average Score: 12.71\n",
      "Episode 510\n",
      " At Episode 510\tBest Average Score: 12.75\n",
      " At Episode 511\tBest Average Score: 12.77\n",
      " At Episode 512\tBest Average Score: 12.82\n",
      " At Episode 513\tBest Average Score: 12.83\n",
      " At Episode 514\tBest Average Score: 12.89\n",
      " At Episode 515\tBest Average Score: 12.97\n",
      " At Episode 516\tBest Average Score: 13.05\n",
      "Parameters saved at Episode 516.00\n",
      "Episode 520\n",
      " At Episode 526\tBest Average Score: 13.06\n",
      "Parameters saved at Episode 526.00\n",
      " At Episode 528\tBest Average Score: 13.09\n",
      "Parameters saved at Episode 528.00\n",
      " At Episode 529\tBest Average Score: 13.18\n",
      "Parameters saved at Episode 529.00\n",
      "Episode 530\n",
      " At Episode 530\tBest Average Score: 13.23\n",
      "Parameters saved at Episode 530.00\n",
      " At Episode 533\tBest Average Score: 13.24\n",
      "Parameters saved at Episode 533.00\n",
      " At Episode 534\tBest Average Score: 13.30\n",
      "Parameters saved at Episode 534.00\n",
      " At Episode 535\tBest Average Score: 13.33\n",
      "Parameters saved at Episode 535.00\n",
      "Episode 540\n",
      " At Episode 543\tBest Average Score: 13.36\n",
      "Parameters saved at Episode 543.00\n",
      " At Episode 545\tBest Average Score: 13.37\n",
      "Parameters saved at Episode 545.00\n",
      " At Episode 546\tBest Average Score: 13.38\n",
      "Parameters saved at Episode 546.00\n",
      "Episode 550\n",
      "Episode 560\n",
      " At Episode 565\tBest Average Score: 13.46\n",
      "Parameters saved at Episode 565.00\n",
      " At Episode 566\tBest Average Score: 13.49\n",
      "Parameters saved at Episode 566.00\n",
      " At Episode 569\tBest Average Score: 13.52\n",
      "Parameters saved at Episode 569.00\n",
      "Episode 570\n",
      " At Episode 570\tBest Average Score: 13.54\n",
      "Parameters saved at Episode 570.00\n",
      " At Episode 571\tBest Average Score: 13.57\n",
      "Parameters saved at Episode 571.00\n",
      " At Episode 572\tBest Average Score: 13.58\n",
      "Parameters saved at Episode 572.00\n",
      " At Episode 573\tBest Average Score: 13.67\n",
      "Parameters saved at Episode 573.00\n",
      " At Episode 574\tBest Average Score: 13.68\n",
      "Parameters saved at Episode 574.00\n",
      "Episode 580\n",
      " At Episode 583\tBest Average Score: 13.73\n",
      "Parameters saved at Episode 583.00\n",
      " At Episode 586\tBest Average Score: 13.80\n",
      "Parameters saved at Episode 586.00\n",
      "Episode 590\n",
      "Episode 600\n",
      " At Episode 603\tBest Average Score: 13.81\n",
      "Parameters saved at Episode 603.00\n",
      " At Episode 607\tBest Average Score: 13.85\n",
      "Parameters saved at Episode 607.00\n",
      "Episode 610\n",
      "Episode 620\n",
      "Episode 630\n",
      " At Episode 635\tBest Average Score: 13.91\n",
      "Parameters saved at Episode 635.00\n",
      " At Episode 636\tBest Average Score: 13.94\n",
      "Parameters saved at Episode 636.00\n",
      " At Episode 639\tBest Average Score: 13.95\n",
      "Parameters saved at Episode 639.00\n",
      "Episode 640\n",
      " At Episode 647\tBest Average Score: 13.97\n",
      "Parameters saved at Episode 647.00\n",
      " At Episode 648\tBest Average Score: 14.07\n",
      "Parameters saved at Episode 648.00\n"
     ]
    }
   ],
   "source": [
    "N_EPISODES = 1000     # maximum number of training episodes\n",
    "MAX_T = 1000          # maximum number of timesteps per episode\n",
    "EPS_START = 1.0       # starting value of epsilon, for epsilon-greedy action selection\n",
    "EPS_END = 0.01        # minimum value of epsilon\n",
    "EPS_DECAY = 0.995     # multiplicative factor (per episode) for decreasing epsilon\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scores = []                                            # storing an array of scores for plotting\n",
    "scores_window = deque(maxlen = 100)                    # Keeping track of 100 episodes' scores to gauge improvement\n",
    "eps = EPS_START                                        # Initializing epsilon\n",
    "best_average = 0\n",
    "for i_episode in range(1, N_EPISODES+1):\n",
    "    env_info = env.reset(train_mode=True)[brain_name]  # reset the environment\n",
    "    state = env_info.vector_observations[0]            # get the current state\n",
    "    score = 0                                          # initialize score per episode\n",
    "    for t in range(MAX_T):\n",
    "        action = agent.act(state, eps)                 # select an action\n",
    "        env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "        next_state = env_info.vector_observations[0]   # get the next state\n",
    "        reward = env_info.rewards[0]                   # get the reward\n",
    "        done = env_info.local_done[0]                  # see if episode has finished\n",
    "        agent.step(state, action, reward, \n",
    "                   next_state, done)\n",
    "        score += reward                                # update the score\n",
    "        state = next_state                             # roll over the state to next time step\n",
    "        \n",
    "        if done:                                       # exit loop if episode finished\n",
    "            break\n",
    "    scores_window.append(score)       # save most recent score\n",
    "    scores.append(score)              # save most recent score\n",
    "    eps = max(EPS_END, EPS_DECAY*eps) # decrease epsilon\n",
    "    if i_episode % 10 == 0:\n",
    "        print(\"Episode {}\".format(i_episode))\n",
    "\n",
    "    if np.mean(scores_window) > best_average:\n",
    "        print('\\r At Episode {}\\tBest Average Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        best_average = np.mean(scores_window)\n",
    "        if np.mean(scores_window)>=13.0:\n",
    "            print('Parameters saved at Episode {:.2f}'.format(i_episode))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "        if np.mean(scores_window) > 14:\n",
    "            break\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Run\n",
    "Do a test run to view the agent in action, and see how high a score it can now attain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 15.0\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "state = env_info.vector_observations[0]\n",
    "score = 0\n",
    "while True:\n",
    "    action = agent.act(state, eps)                 # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    agent.step(state, action, reward, \n",
    "               next_state, done)\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:\n",
    "        break\n",
    "print(\"Score {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "That the agent has managed to attain a reward average of 14 before 1000 episodes, it is safe to say that the neural network implemented is ideal for this project. A possible improvement to the model is an implementation of a prioritized experience-replay, where experiences are sampled based on their TD-error ($R_{t+1} + \\gamma * max_a Q(S_{t+1},a, w) - Q(S_t,A_t,w)$), instead of at random. Other options include the dueling DQN, which mitigates overestimation of the current model, or the Dueling DQN, which identifies which states are valuable for training the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
